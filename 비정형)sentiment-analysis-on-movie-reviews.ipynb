{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_table('/kaggle/input/sentiment-analysis-on-movie-reviews/train.tsv.zip')\ntrain.head()\n# sentiment 1 약간 부정\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Phrase'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test= pd.read_table('/kaggle/input/sentiment-analysis-on-movie-reviews/test.tsv.zip')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\ntk = Tokenizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tk.fit_on_texts(list(train['Phrase']) + list(test['Phrase']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tk.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_text = tk.texts_to_sequences(train['Phrase']) \ntest_text = tk.texts_to_sequences(test['Phrase'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(train_text).apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 그림 - \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize = (20, 12))\nsns.distplot(pd.Series(train_text).apply(len))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 그림 - \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize = (20, 12))\nsns.distplot(pd.Series(test_text).apply(len))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pad_train = pad_sequences(train_text, maxlen= 30) # 너무 긴 거까지 고려하면 과 적합\npad_test = pad_sequences(test_text, maxlen= 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split # 데이터셋 세분화","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(pad_train, train['Sentiment'], random_state=2020, test_size = 0.15, stratify=train['Sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 딥러닝 모델을 쌓는 방법은 2가지\n# 스미싱 텍스트는 스미싱 키워드가 얼마나 들어가 있나가 중요해서 문맥을 고려하는 모델보다 아래 모델\n# 1. 순서대로 쌓는 , \n# 1) 불러오기\nfrom keras import Sequential\nfrom keras.layers import Dense, Embedding, Flatten # 가장 많이쓰는 층 #텍스트에서는 embedding #딥러닝에서는 구조 중요, 차원맞춰줌\n\n# 2) 모델쌓기, 선언\nmodel = Sequential()     # 0도 추가해야함, 단어의 종류에서 그래서 +1\nmodel.add(Embedding(len(tk.word_index)+1,1,input_length=30)) # 차원이 하나면 단어의 의미 분석이 제대로 안됨. 의미의 벡터를 늘려줄 필요가 있다. # 대회 시, 열심히 찾아나가야 되는 부분\n# 1/13 예전보다 하나의 단어의미 자체가 중요해짐(=단어의 길이가 줄면) (보다 독립적). 이에, 차원의 갯수를 늘려주어야함\n# 1/13 input_length는 100보다 커짐. 단어 하나하나가 쪼개지면서 많아짐\n\n#embedding(단어의 의미를 학습한다), 각 데이터에 접근해 스미싱인가 아닌가 *단어*를 보고 판단해야함 \nmodel.add(Flatten()) # 2차원 -> 1차원 \nmodel.add(Dense(5, activation='softmax')) # 옵션2개 중 1개는 정답 클래스 갯수\n# 1일때는 activation='sigmoid' -> 값이 0인 애들이 많이 나옴. 이에 앙상블이 잘 안됨.\nmodel.compile(metrics = ['acc'], optimizer = 'adam', loss='sparse_categorical_crossentropy') # 3가지 옵션 넣어줄거임 * compile, 모델선언 완료\n# 1일때는 binary_crossentropy\n# sparse를 넣어주면 회귀로 인식하는 게 아닌 분류로 인식 + 코드의 간편성을 위해 원핫인코딩 안해도됨 \n# 최적화함수는 최적의 지점을 가는 여러 방법, adam을 주로씀\n# metrics = ['acc'] 정확도 까지 볼 수 있음\n\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint # 라이브러리는 항상 대문자 / 로스가 안좋아지면 과적합으로 판단해 자동으로 멈춰주는 /\n# modelcheckpoint - 모델에서 가장 잘 나온 가중치를 저장하는 \nes = EarlyStopping(patience=3) # 이미지 같은 경우는 평가로스가 많이 튀는 경우가 있어서 5 이상 정도로 \nmc = ModelCheckpoint('best.h5', save_best_only=True) # h5는 가중치를 저장하는 #최적의 순간만 저장하겠다\n\n# 3) 모델 학습\n# model.fit(x_train, y_train, epochs=100, validation_split=0.1,batch_size=128, callbacks=[es,mc]) #callback #batch size는 32가 기본 / 텍스트는 배치가 크면 결과 값이 안나옴, 이미지는 배치가 크면 좋음 \n# x, y 설정 / 학습 횟수 결정, epoch / 학습(90%), 평가(10%)\n\n\nmodel.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid),batch_size=128, callbacks=[es,mc]) #callback #batch size는 32가 기본 / 텍스트는 배치가 크면 결과 값이 안나옴, 이미지는 배치가 크면 좋음 \n# x, y 설정 / 학습 횟수 결정, epoch / 학습(90%), 평가(10%)\n\n\n# 251553/251553 [==============================] - 11s 44us/step - loss: 2.1150e-05 - acc: 1.0000 - val_loss: 6.9053e-04 - val_acc: 0.9998\n# -> random_State 변경하면 0.````3까지 나올 수 이음 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 최적 가중치 저장된 걸 가져와야함 \nmodel.load_weights('best.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict\nresult = model.predict(pad_test, batch_size=128)\nresult\n# 왼쪽 / 오른쪽(), 스미싱 확률","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.argmax(1)\npd.DataFrame(result).idxmax(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/sentiment-analysis-on-movie-reviews/sampleSubmission.csv')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['Sentiment'] = result.argmax(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('baseline_평가셋 수정.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}